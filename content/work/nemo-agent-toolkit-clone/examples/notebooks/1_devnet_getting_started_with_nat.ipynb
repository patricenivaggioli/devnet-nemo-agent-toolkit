{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjRuzfwyImeC"
   },
   "source": [
    "# Getting Started with NeMo Agent Toolkit\n",
    "\n",
    "In this notebook, we walk through the basics of using NVIDIA NeMo Agent toolkit (NAT), from installation all the way to creating and running a simple workflow. The intention of this notebook is to get new NAT users up and running with a high level understanding of our YAML-first approach, while gaining some intuition towards how NAT workflows can quickly be embedded into your projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [0) Setup](#setup)\n",
    "  - [0.1) Prerequisites](#prereqs)\n",
    "  - [0.2) API Keys](#api-keys)\n",
    "  - [0.3) Installing NeMo Agent Toolkit](#installing-nat)\n",
    "- [1) Creating Your First Workflow](#creating-your-first-workflow)\n",
    "  - [1.1) What is a NAT workflow?](#what-is-a-workflow)\n",
    "  - [1.2) Create your first workflow](#create-first-workflow)\n",
    "  - [1.3) Interpret your first workflow](#interpret-first-workflow)\n",
    "    - [Interpreting Directory Structure](#directory-structure)\n",
    "    - [Interpreting Configuration File](#configuration-file)\n",
    "    - [Interpreting Workflow Functions](#workflow-functions)\n",
    "    - [Tying It Together](#tying-it-together)\n",
    "- [2) Running Your First Workflow](#run-first-workflow)\n",
    "    - [2.1) Run with the CLI](#run-cli)\n",
    "    - [2.2) Run as a NAT server](#run-server)\n",
    "    - [2.3) Running NAT Embedded within Python](#run-embedded)\n",
    "- [Next Steps](#next-steps)\n",
    "\n",
    "<span style=\"color:rgb(0, 31, 153); font-style: italic;\">Note: In Google Colab use the Table of Contents tab to navigate.</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFUT0d7NJrtv"
   },
   "source": [
    "<a id=\"setup\"></a>\n",
    "# 0.0) Setup\n",
    "\n",
    "<a id=\"prereqs\"></a>\n",
    "## 0.1) Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4OTdB6wTdRZ"
   },
   "source": [
    "- **Platform:** Linux, macOS, or Windows\n",
    "- **Python:** version 3.11, 3.12, or 3.13\n",
    "- **Python Packages:** `pip`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x50XDSaAJwA4"
   },
   "source": [
    "<a id=\"api-keys\"></a>\n",
    "## 0.2) API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vy8oHmYkJxn6"
   },
   "source": [
    "For this notebook, you will need the following API keys to run all examples end-to-end:\n",
    "\n",
    "- **NVIDIA Build:** You can obtain an NVIDIA Build API Key by creating an [NVIDIA Build](https://build.nvidia.com) account and generating a key at https://build.nvidia.com/settings/api-keys\n",
    "\n",
    "Then you can run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"NVIDIA_API_KEY\" not in os.environ:\n",
    "    nvidia_api_key = getpass.getpass(\"Enter your NVIDIA API key: \")\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvidia_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "azure_prompts = {\n",
    "    \"AZURE_OPENAI_API_KEY\": (\"Enter your Azure OpenAI API key: \", True),\n",
    "    \"AZURE_OPENAI_ENDPOINT\": (\"Enter your Azure OpenAI endpoint URL: \", False),\n",
    "    \"AZURE_OPENAI_DEPLOYMENT\": (\"Enter your Azure OpenAI deployment name: \", False),\n",
    "    \"AZURE_OPENAI_API_VERSION\": (\"Enter your Azure OpenAI API version [2024-05-01-preview]: \", False),\n",
    "}\n",
    "\n",
    "for env_var, (prompt, secret) in azure_prompts.items():\n",
    "    current_value = os.environ.get(env_var, \"\")\n",
    "    if current_value:\n",
    "        continue\n",
    "    if secret:\n",
    "        value = getpass.getpass(prompt)\n",
    "    else:\n",
    "        value = input(prompt).strip()\n",
    "        if not value and env_var == \"AZURE_OPENAI_API_VERSION\":\n",
    "            value = \"2024-05-01-preview\"\n",
    "    if not value:\n",
    "        raise ValueError(f\"A value for {env_var} is required to proceed.\")\n",
    "    os.environ[env_var] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEOYG2b-J1ys"
   },
   "source": [
    "<a id=\"installing-nat\"></a>\n",
    "## 0.3) Installing NeMo Agent Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSICVNHGGm9l"
   },
   "source": [
    "The recommended way to install NAT is through `pip` or `uv pip`.\n",
    "\n",
    "First, we will install `uv` which offers parallel downloads and faster dependency resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install uv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EBV2Gh9NIC8R"
   },
   "source": [
    "NeMo Agent toolkit can be installed through the PyPI `nvidia-nat` package.\n",
    "\n",
    "There are several optional subpackages available for NAT. The `langchain` subpackage contains useful components for integrating and running within [LangChain](https://python.langchain.com/docs/introduction/). Since LangChain will be used later in this notebook, let's install NAT with the optional `langchain` subpackage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install \"nvidia-nat[langchain]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caScQ4VxJ8Ks"
   },
   "source": [
    "<a id=\"creating-your-first-workflow\"></a>\n",
    "# 1.0) Creating Your First Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"what-is-a-workflow\"></a>\n",
    "## 1.1) What is a NAT workflow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7kWJ8yeJJhQ"
   },
   "source": [
    "A [workflow](https://docs.nvidia.com/nemo/agent-toolkit/latest/workflows/about/index.html) in NeMo Agent Toolkit is a structured specification of how agents, models, tools (called functions), embedders, and other components are composed together to carry out a specific task. It defines which components are used, how they are connected, and how they behave when executing the task.\n",
    "\n",
    "NAT provides a convenient command-line interface called `nat` which is accessible in your active Python environment. It serves at the entrypoint to most toolkit functions.\n",
    "\n",
    "The `nat workflow create` command allows us to create a new workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create-first-workflow\"></a>\n",
    "## 1.2) Create your first workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nat workflow create getting_started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSDMOrSQKtBr"
   },
   "source": [
    "<a id=\"interpret-first-workflow\"></a>\n",
    "## 1.3) Interpret your first workflow\n",
    "\n",
    "<a id=\"directory-structure\"></a>\n",
    "### Interpreting Directory Structure\n",
    "We can inspect the structure of the created **workflow directory**, which we've named `getting_started`, and contains the configuration files, source code, and data needed to define and run the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find getting_started/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjBICzW-K0kF"
   },
   "source": [
    "A summary of the high-level components are outlined below.\n",
    "\n",
    "* `configs` (symbolic link to `src/getting_started/configs`)\n",
    "* `data` (symbolic link to `src/getting_started/data`)\n",
    "* `pyproject.toml` Python project configuration file\n",
    "* `src`\n",
    "  * `getting_started`\n",
    "    * `__init__.py` Module init file (empty)\n",
    "    * `configs` Configuration directory for workflow specifications\n",
    "      * `config.yml` Workflow configuration file\n",
    "    * `data` Data directory for any dependent files\n",
    "    * `getting_started.py` User-defined code for workflow execution\n",
    "    * `register.py` Automatic registration of project components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAsjWuDSTjbC"
   },
   "source": [
    "<a id=\"configuration-file\"></a>\n",
    "### Interpreting Configuration File\n",
    "The workflow configuration file, `getting_started/configs/config.yml`, describes the operational characteristics of the entire workflow. Let's load its contents in the next cell and understand what this first workflow can do out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load getting_started/configs/config.yml\n",
    "functions:\n",
    "  current_datetime:\n",
    "    _type: current_datetime\n",
    "  getting_started:\n",
    "    _type: getting_started\n",
    "    prefix: 'Hello:'\n",
    "llms:\n",
    "  azure_llm:\n",
    "    _type: azure_openai\n",
    "    azure_endpoint: ${AZURE_OPENAI_ENDPOINT}\n",
    "    azure_deployment: ${AZURE_OPENAI_DEPLOYMENT}\n",
    "    api_key: ${AZURE_OPENAI_API_KEY}\n",
    "    api_version: 2024-05-01-preview\n",
    "\n",
    "workflow:\n",
    "  _type: react_agent\n",
    "  llm_name: azure_llm\n",
    "  tool_names:\n",
    "  - current_datetime\n",
    "  - getting_started\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated getting_started/configs/config.yml to use Azure OpenAI.\n"
     ]
    }
   ],
   "source": [
    "# Switch the workflow to Azure OpenAI\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import yaml\n",
    "except ImportError:\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pyyaml\"], check=True)\n",
    "    import yaml\n",
    "\n",
    "config_path = Path(\"getting_started/configs/config.yml\")\n",
    "if not config_path.exists():\n",
    "    raise FileNotFoundError(f\"Workflow config not found at {config_path}\")\n",
    "\n",
    "with config_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    config_data = yaml.safe_load(f)\n",
    "\n",
    "config_data[\"llms\"] = {\n",
    "    \"azure_llm\": {\n",
    "        \"_type\": \"azure_openai\",\n",
    "        \"azure_endpoint\": \"${AZURE_OPENAI_ENDPOINT}\",\n",
    "        \"azure_deployment\": \"${AZURE_OPENAI_DEPLOYMENT}\",\n",
    "        \"api_key\": \"${AZURE_OPENAI_API_KEY}\",\n",
    "        \"api_version\": \"2024-05-01-preview\",\n",
    "    }\n",
    "}\n",
    "config_data.setdefault(\"workflow\", {})\n",
    "config_data[\"workflow\"][\"llm_name\"] = \"azure_llm\"\n",
    "\n",
    "with config_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(config_data, f, sort_keys=False)\n",
    "\n",
    "print(f\"Updated {config_path} to use Azure OpenAI.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6D026_fM-h2"
   },
   "source": [
    "The above workflow configuration has the following components:\n",
    "- a [built-in `current_datetime`](https://docs.nvidia.com/nemo/agent-toolkit/latest/api/nat/tool/datetime_tools/index.html#nat.tool.datetime_tools.current_datetime) function\n",
    "- a workflow-defined `getting_started` function\n",
    "- an LLM\n",
    "- an entrypoint workflow of a [built-in ReAct agent](https://docs.nvidia.com/nemo/agent-toolkit/latest/workflows/about/react-agent.html)\n",
    "\n",
    "By default, we create a [ReAct agent](https://docs.nvidia.com/nemo/agent-toolkit/latest/workflows/about/react-agent.html) equipped with both of the functions above. When called, the Agent decides which functions to call (if any) based on the intent of user input. The agent uses the LLM to help make reasoning decisions and then performs a subsequent action.\n",
    "\n",
    "This workflow configuration file is a YAML-serialized version of the [`Config`](https://docs.nvidia.com/nemo/agent-toolkit/latest/api/nat/data_models/config/index.html#nat.data_models.config.Config) class. Each category within the high-level configuration specifies runtime configuration settings for their corresponding components. For instance, the `workflow` category contains all configuration settings for the workflow entrypoint. This configuration file is validated as typed Pydantic models and fields. All configuration classes have validation rules, default values, and [documentation](https://docs.nvidia.com/nemo/agent-toolkit/latest/workflows/workflow-configuration.html#workflow-configuration-file) which enable type-safe configuration management, automatic schema generation, and validation across the entire plugin ecosystem.\n",
    "\n",
    "* `general` - General configuration section. Contains high-level configurations for front-end definitions.\n",
    "* `authentication` - Authentication provides an interface for defining and interacting with various authentication providers.\n",
    "* `llms` - LLMs provide an interface for interacting with LLM providers.\n",
    "* `embedders` - Embedders provide an interface for interacting with embedding model providers.\n",
    "* `retreivers` - Retrievers provide an interface for searching and retrieving documents.\n",
    "* `memory` - Configurations for Memory. Memories provide an interface for storing and retrieving.\n",
    "* `object_stores` - Object Stores provide a CRUD interface for objects and data.\n",
    "* `eval` - The evaluation section provides configuration options related to the profiling and evaluation of NAT workflows.\n",
    "* `tcc_strategies` (experimental) - Test Time Compute (TTC) strategy definitions.\n",
    "\n",
    "#### Type Safety and Validation\n",
    "\n",
    "Many components within the workflow configuration specify `_type`. This YAML key is used to indicate the type of the component so NAT can properly validate and instantiate a component within the workflow. For example, [`NIMModelConfig`](https://docs.nvidia.com/nemo/agent-toolkit/latest/api/nat/llm/nim_llm/index.html#nat.llm.nim_llm.NIMModelConfig) is a subclass of [`LLMBaseConfig`](https://docs.nvidia.com/nemo/agent-toolkit/latest/api/nat/data_models/llm/index.html#nat.data_models.llm.LLMBaseConfig) so when we specify: `_type: nim` in the configuration the toolkit knows to validate the configuration with `NIMModelConfig`.\n",
    "\n",
    "<span style=\"color:rgb(0, 31, 153); font-style: italic;\">**Note:** Not all configuration components are required. The simplest workflow configuration needs to only define <code>workflow</code>.</span>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPLvWYvtTpNF"
   },
   "source": [
    "<a id=\"workflow-functions\"></a>\n",
    "## 1.4) Interpreting Workflow Functions\n",
    "\n",
    "Next, let's inspect the contents of the generated workflow function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load getting_started/src/getting_started/getting_started.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3H5fib-jTvwq"
   },
   "source": [
    "### Function Configuration\n",
    "\n",
    "The `GettingStartedFunctionConfig` specifies `FunctionBaseConfig` as a base class. There is also a `name` specified. This name is used by the toolkit to create a static mapping when `_type` is specified anywhere where a `FunctionBaseConfig` is expected, such as `workflow` or under `functions`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WncUuuuTxxa"
   },
   "source": [
    "### Function Registration\n",
    "\n",
    "NeMo Agent toolkit relies on a configuration with builder pattern to define most components. For functions, `@register_function` is a decorator that must be specified to inform the toolkit that a function should be accessible automatically by name when referenced. The decorator requires that a `config_type` is specified. This is done to ensure type safety and validation.\n",
    "\n",
    "The parameters to the decorated function are always:\n",
    "\n",
    "1. the configuration type of the function component (FunctionBaseConfig)\n",
    "2. a Builder which can be used to dynamically query and get other workflow components (Builder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KI8H8IoqT0TX"
   },
   "source": [
    "### Function Implementation\n",
    "\n",
    "The core logic of the `getting_started` function is embedded as a function within the outer function registration. This is done for a few reasons:\n",
    "\n",
    "* Enables dynamic importing of libraries and modules on an as-needed basis.\n",
    "* Enables context manager-like resources within to support automatic closing of resources.\n",
    "* Provides the most flexibility to users when defining their own functions.\n",
    "\n",
    "Near the end of the function registration implementation, we `yield` a `FunctionInfo` object. `FunctionInfo` is a wrapper around any type of function. It is also possible to specify additional information such as schema and converters if your function relies on transformations.\n",
    "\n",
    "NAT relies on `yield` rather `return` so resources can stay alive during the lifetime of the function or workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYfRqWaQBHLT"
   },
   "source": [
    "<a id=\"tying-it-together\"></a>\n",
    "### Tying It Together\n",
    "\n",
    "Looking back at the configuration file, the `workflow`'s `_type` is `getting_started`. This means that the configuration of `workflow` will be validated based on the `GettingStartedFunctionConfig` implementation.\n",
    "\n",
    "The `register.py` file tells NAT what should automatically be imported so it is available when the toolkit is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load getting_started/src/getting_started/register.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxP2QC1rT9UQ"
   },
   "source": [
    "<a id=\"run-first-workflow\"></a>\n",
    "# 2.0) Running Your First Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9D7yNW7ySCaY"
   },
   "source": [
    "<a id=\"run-cli\"></a>\n",
    "## 2.1) Run with the CLI\n",
    "\n",
    "You can run a workflow by using `nat run` CLI command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-22 18:47:53 - INFO     - nat.cli.commands.start:192 - Starting NAT from config file: 'getting_started/configs/config.yml'\n",
      "\n",
      "Configuration Summary:\n",
      "--------------------\n",
      "Workflow Type: react_agent\n",
      "Number of Functions: 2\n",
      "Number of Function Groups: 0\n",
      "Number of LLMs: 1\n",
      "Number of Embedders: 0\n",
      "Number of Memory: 0\n",
      "Number of Object Stores: 0\n",
      "Number of Retrievers: 0\n",
      "Number of TTC Strategies: 0\n",
      "Number of Authentication Providers: 0\n",
      "\n",
      "2025-12-22 18:47:59 - INFO     - nat.front_ends.console.console_front_end_plugin:102 - --------------------------------------------------\n",
      "\u001b[32mWorkflow Result:\n",
      "['Hello, Will! How can I assist you today?']\u001b[39m\n",
      "--------------------------------------------------\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!nat run --config_file getting_started/configs/config.yml \\\n",
    "         --input \"Can you echo back my name, Will?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "628pQAJLSJHF"
   },
   "source": [
    "<a id=\"run-server\"></a>\n",
    "## 2.2) Run as a NAT server\n",
    "\n",
    "NAT provides another mechanism for running workflows through `nat serve`. `nat serve` creates and launches a REST FastAPI web server for interfacing with the toolkit as though it was an OpenAI-compatible endpoint. To learn more about all endpoints served by `nat serve`, please consult [this documentation](https://docs.nvidia.com/nemo/agent-toolkit/latest/reference/api-server-endpoints.html).\n",
    "\n",
    "<span style=\"color: red\"><i>note: If running this notebook in a cloud provider such as Google Colab, `dask` may be installed. If it is, you will first have to uninstall it via:</i></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAk1zzpjWaTF"
   },
   "source": [
    "To start the FastAPI web server, issue the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "nat serve --config_file getting_started/configs/config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXbyoAnJSq-v"
   },
   "source": [
    "It will take several seconds for the server to be reachable. The default port for the server is `8000` with `localhost` access.\n",
    "\n",
    "Note that `--input` was not required for `nat serve`. To issue a request to the server, you can then do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   496  100   368  100   128     91     39  0:00:03  0:00:03 --:--:--    39 31  0:00:04  0:00:04 --:--:--   122100   368  100   128     91     31  0:00:04  0:00:04 --:--:--   122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"5cd2c2bc-59d4-4e53-b7dd-1bf5d283cda6\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"model\": \"unknown-model\",\n",
      "  \"created\": 1766425851,\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"The current time is 2025-12-22 17:50:49 +0000.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 5,\n",
      "    \"completion_tokens\": 7,\n",
      "    \"total_tokens\": 12\n",
      "  },\n",
      "  \"system_fingerprint\": null,\n",
      "  \"service_tier\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Issue a request to the background service\n",
    "curl --request POST \\\n",
    "  --url http://localhost:8000/chat \\\n",
    "  --header 'Content-Type: application/json' \\\n",
    "  --data '{\n",
    "    \"messages\": [\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": \"What is the current time?\"\n",
    "        }\n",
    "      ]\n",
    "    }' | jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminate the process after completion\n",
    "!pkill -9 -f \"nat serve\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jTB70LnW2it"
   },
   "source": [
    "<a id=\"run-embedded\"></a>\n",
    "## 2.3) Running NAT Embedded within Python\n",
    "\n",
    "The final way to run a NAT workflow is by embedding it into an already existing Python application or library.\n",
    "\n",
    "Consider the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing nat_embedded.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile nat_embedded.py\n",
    "import asyncio\n",
    "import sys\n",
    "\n",
    "from nat.runtime.loader import load_workflow\n",
    "from nat.utils.type_utils import StrPath\n",
    "\n",
    "\n",
    "async def get_callable_for_workflow(config_file: StrPath):\n",
    "    \"\"\"\n",
    "    Creates an end-to-end async callable which can run a NAT workflow.\n",
    "\n",
    "    Note that this \"yields\" the callable so you have to access via an\n",
    "    asynchronous generator:\n",
    "\n",
    "      async for callable in get_callable_for_workflow(..)):\n",
    "          # use callable here\n",
    "\n",
    "    Args:\n",
    "        config_file (StrPath): a valid path to a NAT configuration file\n",
    "\n",
    "    Yields:\n",
    "        The callable\n",
    "    \"\"\"\n",
    "    # load a given workflow from a configuration file\n",
    "    async with load_workflow(config_file) as workflow:\n",
    "\n",
    "        # create an async callable that runs the workflow\n",
    "        async def single_call(input_str: str) -> str:\n",
    "\n",
    "            # run the input through the workflow\n",
    "            async with workflow.run(input_str) as runner:\n",
    "                # wait for the result and cast it to a string\n",
    "                return await runner.result(to_type=str)\n",
    "\n",
    "        yield single_call\n",
    "\n",
    "\n",
    "async def amain():\n",
    "    async for callable in get_callable_for_workflow(sys.argv[1]):\n",
    "        # read queries from stdin and process them serially\n",
    "        query_num = 1\n",
    "        try:\n",
    "            while True:\n",
    "                query = input()\n",
    "                result = await callable(query)\n",
    "                print(f\"Query {query_num}: {query}\")\n",
    "                print(f\"Result {query_num}: {result}\")\n",
    "                query_num += 1\n",
    "        except EOFError:\n",
    "            pass\n",
    "\n",
    "\n",
    "asyncio.run(amain())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27FCs1byYlYb"
   },
   "source": [
    "Then we can run it as a normal Python program as shown below, or better yet, integrate with your existing services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: What are you capable of doing?\n",
      "Result 1: I can answer questions, provide information, assist with tasks, and use tools like checking the current date and time or echoing back text with a prefix. Let me know how I can assist you!\n",
      "Query 2: What does the 'current_datetime' tool do?\n",
      "Result 2: The 'current_datetime' tool returns the current date and time in human-readable format with timezone information.\n",
      "Query 3: What does the 'getting_started' tool do?\n",
      "Result 3: The 'getting_started' tool takes a text input and echoes it back with a pre-defined prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[AGENT] Failed to parse agent output after 1 attempts, consider enabling or increasing parse_agent_response_max_retries\n",
      "[AGENT] Failed to parse agent output after 1 attempts, consider enabling or increasing parse_agent_response_max_retries\n",
      "[AGENT] Failed to parse agent output after 1 attempts, consider enabling or increasing parse_agent_response_max_retries\n",
      "[AGENT] Failed to parse agent output after 1 attempts, consider enabling or increasing parse_agent_response_max_retries\n",
      "[AGENT] Failed to parse agent output after 1 attempts, consider enabling or increasing parse_agent_response_max_retries\n",
      "[AGENT] Failed to parse agent output after 1 attempts, consider enabling or increasing parse_agent_response_max_retries\n",
      "[AGENT] Failed to parse agent output after 1 attempts, consider enabling or increasing parse_agent_response_max_retries\n",
      "[AGENT] Failed to parse agent output after 1 attempts, consider enabling or increasing parse_agent_response_max_retries\n",
      "[AGENT] Failed to parse agent output after 1 attempts, consider enabling or increasing parse_agent_response_max_retries\n",
      "[AGENT] Failed to parse agent output after 1 attempts, consider enabling or increasing parse_agent_response_max_retries\n",
      "[AGENT] Failed to parse agent output after 1 attempts, consider enabling or increasing parse_agent_response_max_retries\n",
      "[AGENT] Failed to parse agent output after 1 attempts, consider enabling or increasing parse_agent_response_max_retries\n",
      "[AGENT] Failed to parse agent output after 1 attempts, consider enabling or increasing parse_agent_response_max_retries\n",
      "[AGENT] Failed to parse agent output after 1 attempts, consider enabling or increasing parse_agent_response_max_retries\n",
      "[AGENT] Failed to parse agent output after 1 attempts, consider enabling or increasing parse_agent_response_max_retries\n",
      "[AGENT] ReAct Agent failed with exception: Recursion limit of 32 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT\n",
      "Error with ainvoke in function with input: What is the current time?. Error: Recursion limit of 32 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT\n",
      "Error running workflow: Recursion limit of 32 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pnivaggi/Library/CloudStorage/OneDrive-Cisco/dev/nemo-agent-toolkit-clone/examples/notebooks/nat_embedded.py\", line 53, in <module>\n",
      "    asyncio.run(amain())\n",
      "  File \"/Users/pnivaggi/.local/share/uv/python/cpython-3.12.11-macos-aarch64-none/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pnivaggi/.local/share/uv/python/cpython-3.12.11-macos-aarch64-none/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pnivaggi/.local/share/uv/python/cpython-3.12.11-macos-aarch64-none/lib/python3.12/asyncio/base_events.py\", line 691, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pnivaggi/Library/CloudStorage/OneDrive-Cisco/dev/nemo-agent-toolkit-clone/examples/notebooks/nat_embedded.py\", line 45, in amain\n",
      "    result = await callable(query)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pnivaggi/Library/CloudStorage/OneDrive-Cisco/dev/nemo-agent-toolkit-clone/examples/notebooks/nat_embedded.py\", line 33, in single_call\n",
      "    return await runner.result(to_type=str)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pnivaggi/Library/CloudStorage/OneDrive-Cisco/dev/.venv/lib/python3.12/site-packages/nat/runtime/runner.py\", line 175, in result\n",
      "    result = await self._entry_fn.ainvoke(self._input_message, to_type=to_type)  # type: ignore\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pnivaggi/Library/CloudStorage/OneDrive-Cisco/dev/.venv/lib/python3.12/site-packages/nat/builder/function.py\", line 153, in ainvoke\n",
      "    result = await self._ainvoke(converted_input)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pnivaggi/Library/CloudStorage/OneDrive-Cisco/dev/.venv/lib/python3.12/site-packages/nat/builder/function.py\", line 329, in _ainvoke\n",
      "    return await self._ainvoke_fn(value)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pnivaggi/Library/CloudStorage/OneDrive-Cisco/dev/.venv/lib/python3.12/site-packages/nat/agent/react_agent/register.py\", line 145, in _response_fn\n",
      "    state = await graph.ainvoke(state, config={'recursion_limit': (config.max_tool_calls + 1) * 2})\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pnivaggi/Library/CloudStorage/OneDrive-Cisco/dev/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py\", line 3171, in ainvoke\n",
      "    async for chunk in self.astream(\n",
      "  File \"/Users/pnivaggi/Library/CloudStorage/OneDrive-Cisco/dev/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py\", line 3036, in astream\n",
      "    raise GraphRecursionError(msg)\n",
      "langgraph.errors.GraphRecursionError: Recursion limit of 32 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b\"python nat_embedded.py getting_started/configs/config.yml <<EOF\\nWhat are you capable of doing?\\nWhat does the 'current_datetime' tool do?\\nWhat does the 'getting_started' tool do?\\nWhat is the current time?\\nCan you echo back my name, Evan?\\nWhat is the current time?\\nCan you echo back my name, Will?\\nEOF\\n\"' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCalledProcessError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbash\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpython nat_embedded.py getting_started/configs/config.yml <<EOF\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mWhat are you capable of doing?\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mWhat does the \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcurrent_datetime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m tool do?\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mWhat does the \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgetting_started\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m tool do?\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mWhat is the current time?\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mCan you echo back my name, Evan?\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mWhat is the current time?\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mCan you echo back my name, Will?\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mEOF\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Cisco/dev/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2565\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2564\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2568\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2569\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Cisco/dev/.venv/lib/python3.12/site-packages/IPython/core/magics/script.py:160\u001b[39m, in \u001b[36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[39m\u001b[34m(line, cell)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    159\u001b[39m     line = script\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Cisco/dev/.venv/lib/python3.12/site-packages/IPython/core/magics/script.py:343\u001b[39m, in \u001b[36mScriptMagics.shebang\u001b[39m\u001b[34m(self, line, cell)\u001b[39m\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args.raise_error \u001b[38;5;129;01mand\u001b[39;00m p.returncode != \u001b[32m0\u001b[39m:\n\u001b[32m    339\u001b[39m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[32m    340\u001b[39m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[32m    341\u001b[39m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[32m    342\u001b[39m     rc = p.returncode \u001b[38;5;129;01mor\u001b[39;00m -\u001b[32m9\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[31mCalledProcessError\u001b[39m: Command 'b\"python nat_embedded.py getting_started/configs/config.yml <<EOF\\nWhat are you capable of doing?\\nWhat does the 'current_datetime' tool do?\\nWhat does the 'getting_started' tool do?\\nWhat is the current time?\\nCan you echo back my name, Evan?\\nWhat is the current time?\\nCan you echo back my name, Will?\\nEOF\\n\"' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python nat_embedded.py getting_started/configs/config.yml <<EOF\n",
    "What are you capable of doing?\n",
    "What does the 'current_datetime' tool do?\n",
    "What does the 'getting_started' tool do?\n",
    "What is the current time?\n",
    "Can you echo back my name, Evan?\n",
    "What is the current time?\n",
    "Can you echo back my name, Will?\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEtrDDQUjSpX"
   },
   "source": [
    "<a id=\"next-steps\"></a>\n",
    "# 3.0) Next Steps\n",
    "\n",
    "If you already have agents codified and don't need NAT to bring up your first agent, we also support bringing existing agents into the NAT framework. In the next notebook of this series, \\\"Bringing Your Own Agent into NeMo Agent Toolkit\\\" (2_bringing_your_own_agent.ipynb), we will walk you through adapting existing agents into NAT."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dev venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
