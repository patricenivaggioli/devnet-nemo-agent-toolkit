# SPDX-FileCopyrightText: Copyright (c) 2024-2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This config file shows how to use the MCP server to get the current date and time.
# Here the workflow acts as a MCP client and connects to the MCP server running
# on the specified URL. streamable-http is the recommended transport for HTTP-based
# connections, but sse is also supported for backwards compatibility.

# This config file shows -
# 1. how to use a local MCP server to get the current date and time using stdio transport.
# 2. how to access a remote MCP server using streamable-http transport for math operations.
#
# As the mcp_server_time is running locally ensure that the package "mcp_server_time" is installed
# on your local machine. For example, if you are using pip, you can install it with:
# uv pip install mcp-server-time

# Sample usage:
# nat run --config_file config-mcp-auth-jira.yml --input "What is jira ticket AIQ-1935 about"

function_groups:
  mcp_jira:
    _type: mcp_client
    server:
      transport: streamable-http
      url: ${CORPORATE_MCP_JIRA_URL}
      auth_provider: mcp_oauth2_jira

authentication:
  mcp_oauth2_jira:
    _type: mcp_oauth2
    server_url: ${CORPORATE_MCP_JIRA_URL}
    redirect_uri: ${NAT_REDIRECT_URI:-http://localhost:8000/auth/redirect}
    default_user_id: ${NAT_USER_ID}
    allow_default_user_id_for_tool_calls: ${ALLOW_DEFAULT_USER_ID_FOR_TOOL_CALLS:-true}

llms:
  nim_llm:
    _type: nim
    model_name: meta/llama-3.1-70b-instruct
    temperature: 0.0
    max_tokens: 1024

workflow:
  _type: react_agent
  tool_names:
    - mcp_jira
  llm_name: nim_llm
  verbose: true
  retry_parsing_errors: true
  max_retries: 3
